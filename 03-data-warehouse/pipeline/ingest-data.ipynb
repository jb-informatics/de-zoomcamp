{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f97a9479-06a3-40b9-8f0b-6433071e19fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv pip install google-cloud-bigquery-storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1ca7450-5cc4-4135-89da-7ad6bab0abc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !uv pip install dlt[bigquery] requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ff81ccee-9dc6-4ef1-9dc9-0e43543d82f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import dlt\n",
    "import requests\n",
    "from google.cloud import bigquery_storage\n",
    "from google.cloud import bigquery\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "from tqdm.notebook import tqdm\n",
    "from dlt.destinations import filesystem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2a100851-a657-4799-bff1-a22f0eba86b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using credentials: /workspaces/de-zoomcamp/03-data-warehouse/pipeline/terraform/keys.json\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ROOT = os.getcwd()\n",
    "TERRAFORM_DIR = os.path.join(PROJECT_ROOT, \"terraform\")\n",
    "KEYS_PATH = os.path.join(TERRAFORM_DIR, \"keys.json\")\n",
    "\n",
    "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = KEYS_PATH\n",
    "os.environ[\"DESTINATION__BIGQUERY__LOCATION\"] = \"US\"\n",
    "os.environ[\"BUCKET_URL\"] = \"gs://de-zoomcamp-terraform-484919-data-lake\"\n",
    "\n",
    "print(\"Using credentials:\", os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9d191cc-2ab4-4576-a0a4-7bd784f9115f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Authenticated project: de-zoomcamp-terraform-484919\n"
     ]
    }
   ],
   "source": [
    "client = bigquery.Client()\n",
    "print(\"Authenticated project:\", client.project)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81a0c757-f28e-4c81-9621-dbe910531c1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# -----------------------------\n",
    "# Create the pipeline\n",
    "# -----------------------------\n",
    "pipeline_bq = dlt.pipeline(\n",
    "    pipeline_name=\"nyc_taxi_pipeline\",\n",
    "    destination=\"bigquery\",\n",
    "    dataset_name=\"nyc_taxi_dataset\",\n",
    ")\n",
    "\n",
    "pipeline_gcs = dlt.pipeline(\n",
    "    pipeline_name=\"nyc_taxi_pipeline\",\n",
    "    destination=filesystem(layout=\"{schema_name}/{table_name}.{ext}\"),\n",
    "    dataset_name=\"nyc_taxi_dataset\",\n",
    ")\n",
    "\n",
    "# -----------------------------\n",
    "# List of months to fetch\n",
    "# -----------------------------\n",
    "months = range(1, 7)\n",
    "\n",
    "# -----------------------------\n",
    "# Process one month at a time\n",
    "# -----------------------------\n",
    "for month in tqdm(months, desc=\"Processing months\", unit=\"month\"):\n",
    "    url = f\"https://d37ci6vzurychx.cloudfront.net/trip-data/yellow_tripdata_2024-{month:02d}.parquet\"\n",
    "    print(f\"Fetching month {month}: {url}\")\n",
    "\n",
    "    # Download Parquet file\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    df = pd.read_parquet(BytesIO(response.content))\n",
    "\n",
    "    # # Create a temporary dlt source for this single month\n",
    "    @dlt.source(name=f\"yellow_tripdata_2024_dataset\")\n",
    "    def process_bigquery():\n",
    "        yield dlt.resource(df, name=\"yellow_tripdata_2024\")  # same table name for all months\n",
    "\n",
    "    @dlt.source(name=f\"yellow_tripdata_2024\")\n",
    "    def process_gcs_bucket():\n",
    "        yield dlt.resource(df, name=f\"yellow_tripdata_2024_{month:02d}\")\n",
    "\n",
    "    # Run pipeline\n",
    "    load_info = pipeline_bq.run(process_bigquery(), loader_file_format=\"parquet\")\n",
    "    print(f\"Month {month} loaded. Info: {load_info}\")\n",
    "    \n",
    "    load_info = pipeline_gcs.run(process_gcs_bucket(), loader_file_format=\"parquet\")\n",
    "    print(f\"Month {month} loaded. Info: {load_info}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e4abd3-9b8b-4da4-a8c5-7816825b8092",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = f\"\"\"\n",
    "    SELECT COUNT(*) AS row_count FROM `{client.project}.nyc_taxi_dataset.yellow_tripdata_2024`\n",
    "\"\"\"\n",
    "\n",
    "# Execute the query\n",
    "result = client.query(query).result()\n",
    "total_rows = [row.row_count for row in result][0]\n",
    "\n",
    "print(f\"Total number of rows across all 6 months: {total_rows}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
